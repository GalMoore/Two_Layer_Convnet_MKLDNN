// Generated by the nGraph CPU backend
//Enhanced by automated code generator Brain team

#include <cmath>
#include <fstream>
#include <mkldnn.hpp>
#include "aligned_buffer.hpp"
#include <iostream>
#include <mkldnn_debug.h>
//#include "ngraph/distributed.hpp"
//#include "ngraph/except.hpp"
//#include "ngraph/runtime/aligned_buffer.hpp"
//#include "ngraph/runtime/cpu/cpu_eigen_utils.hpp"
//#include "ngraph/runtime/cpu/cpu_executor.hpp"
//#include "ngraph/runtime/cpu/cpu_kernels.hpp"
//#include "ngraph/runtime/cpu/cpu_runtime_context.hpp"
//#include "ngraph/runtime/cpu/mkldnn_invoke.hpp"
//#include "ngraph/runtime/cpu/mkldnn_utils.hpp"
//#include "ngraph/runtime/reference/all.hpp"
//#include "ngraph/runtime/reference/and.hpp"
//#include "ngraph/runtime/reference/any.hpp"
//#include "ngraph/runtime/reference/argmax.hpp"
//#include "ngraph/runtime/reference/argmin.hpp"
//#include "ngraph/runtime/reference/avg_pool.hpp"
//#include "ngraph/runtime/reference/batch_norm.hpp"
//#include "ngraph/runtime/reference/broadcast.hpp"
//#include "ngraph/runtime/reference/concat.hpp"
//#include "ngraph/runtime/reference/convolution.hpp"
//#include "ngraph/runtime/reference/dequantize.hpp"
//#include "ngraph/runtime/reference/dot.hpp"
//#include "ngraph/runtime/reference/embedding_lookup.hpp"
//#include "ngraph/runtime/reference/gather.hpp"
//#include "ngraph/runtime/reference/gather_nd.hpp"
//#include "ngraph/runtime/reference/generate_mask.hpp"
//#include "ngraph/runtime/reference/lrn.hpp"
//#include "ngraph/runtime/reference/max.hpp"
//#include "ngraph/runtime/reference/max_pool.hpp"
//#include "ngraph/runtime/reference/min.hpp"
//#include "ngraph/runtime/reference/not.hpp"
//#include "ngraph/runtime/reference/one_hot.hpp"
//#include "ngraph/runtime/reference/or.hpp"
//#include "ngraph/runtime/reference/pad.hpp"
//#include "ngraph/runtime/reference/product.hpp"
//#include "ngraph/runtime/reference/quantize.hpp"
//#include "ngraph/runtime/reference/relu.hpp"
//#include "ngraph/runtime/reference/replace_slice.hpp"
//#include "ngraph/runtime/reference/reshape.hpp"
//#include "ngraph/runtime/reference/result.hpp"
//#include "ngraph/runtime/reference/reverse.hpp"
//#include "ngraph/runtime/reference/reverse_sequence.hpp"
//#include "ngraph/runtime/reference/scatter_add.hpp"
//#include "ngraph/runtime/reference/scatter_nd_add.hpp"
//#include "ngraph/runtime/reference/slice.hpp"
//#include "ngraph/runtime/reference/sum.hpp"
//#include "ngraph/runtime/reference/topk.hpp"
//#include "ngraph/runtime/reference/xor.hpp"
//#include "ngraph/shape.hpp"
//#include "ngraph/state/bernoulli_rng_state.hpp"
//#include "ngraph/strides.hpp"
//#include "ngraph/util.hpp"
using namespace std;

//using namespace ngraph::runtime::cpu::eigen;
//using namespace ngraph::runtime;

//void *__dso_handle = 0;

// Declare all constants
static float Constant_1_0[2800/sizeof(float)];
static float Constant_3_0[40/sizeof(float)];
static float Constant_7_0[720/sizeof(float)];
static float Constant_9_0[8/sizeof(float)];
extern "C" void load_params()
{
	std:ifstream params_file;
	std::string weight_file_name = "/home/gal/code/ONE_LAYER_CONV_MKL_TOOLCHAIN/weights_and_biases/conv1.weight";

	params_file.open(weight_file_name, ios::in|ios::binary);
	if (params_file.fail())
	{cout << 'Failed to load at file: ' << __FILE__ << ' line: ' << __LINE__ << endl << endl;
	exit(0);}
	params_file.read((char*)Constant_1_0,2800);
	params_file.close();

	weight_file_name = "/home/gal/code/ONE_LAYER_CONV_MKL_TOOLCHAIN/weights_and_biases/conv1.bias";
	params_file.open(weight_file_name, ios::in|ios::binary);
	if (params_file.fail())
	{cout << 'Failed to load at file: ' << __FILE__ << ' line: ' << __LINE__ << endl << endl;
	exit(0);}
	params_file.read((char*)Constant_3_0,40);
	params_file.close();

	weight_file_name = "/home/gal/code/ONE_LAYER_CONV_MKL_TOOLCHAIN/weights_and_biases/conv2.weight";
	params_file.open(weight_file_name, ios::in|ios::binary);
	if (params_file.fail())
	{cout << 'Failed to load at file: ' << __FILE__ << ' line: ' << __LINE__ << endl << endl;
	exit(0);}
	params_file.read((char*)Constant_7_0,720);
	params_file.close();

	weight_file_name = "/home/gal/code/ONE_LAYER_CONV_MKL_TOOLCHAIN/weights_and_biases/conv2.bias";
	params_file.open(weight_file_name, ios::in|ios::binary);
	if (params_file.fail())
	{cout << 'Failed to load at file: ' << __FILE__ << ' line: ' << __LINE__ << endl << endl;
	exit(0);}
	params_file.read((char*)Constant_9_0,8);
	params_file.close();

}
// Declare all classes
struct CPURuntimeContextCG;
struct CPURuntimeContext;
// Declare all functions
//extern "C" void Function_0(void** inputs, void** outputs, cpu::CPURuntimeContext* ctx, CPURuntimeContextCG* cg_ctx);
extern "C" void Function_0(void** inputs, void** outputs, CPURuntimeContext* ctx, CPURuntimeContextCG* cg_ctx);


                enum class OpType
                {
                    ADD,
                    AVGPOOL,
                    AVGPOOLBACKPROP,
                    BATCHNORM3ARGS,
                    BATCHNORM5ARGS,
                    BATCHNORMBACKPROP,
                    BOUNDEDRELU,
                    CONCAT,
                    CONVERTLAYOUT,
                    CONVOLUTION,
                    CONVOLUTIONRELU,
                    CONVOLUTIONADD,
                    CONVOLUTIONBIAS,
                    CONVOLUTIONBIASADD,
                    CONVOLUTIONBACKPROPDATA,
                    CONVOLUTIONBACKPROPWEIGHTS,
                    CONVOLUTIONBIASBACKPROPWEIGHTSBIAS,
                    GROUPCONVOLUTION,
                    GROUPCONVOLUTIONBIAS,
                    DECONVOLUTIONBIAS,
                    LEAKYRELU,
                    LRN,
                    LSTM,
                    MAXPOOL,
                    MAXPOOLBACKPROPFORWARD,
                    MAXPOOLBACKPROPBACKWARD,
                    MAXPOOLWITHINDICES,
                    MAXPOOLWITHINDICESBACKPROP,
                    QUANTIZE,
                    DEQUANTIZE,
                    QUANTIZEDAVGPOOL,
                    QUANTIZEDMAXPOOL,
                    QUANTIZEDCONCAT,
                    QUANTIZEDDOTBIAS,
                    QUANTIZEDMATMUL,
                    QUANTIZEDCONVOLUTION,
                    QUANTIZEDCONVOLUTIONBIAS,
                    QUANTIZEDCONVOLUTIONBIASADD,
                    QUANTIZEDCONVOLUTIONBIASSIGNEDADD,
                    QUANTIZEDCONVOLUTIONRELU,
                    RELU,
                    RELUBACKPROP,
                    RNN,
                    SIGMOID,
                    SIGMOIDBACKPROP,
                    SLICE,
                    SOFTMAX
                };
struct CPURuntimeContext
{
//	int64_t* op_durations;
	bool* p_en;
	bool first_iteration;
	// stores tensor pointers
//	std::vector<void*> buffer_data;
//	std::vector<mkldnn::memory*> mkldnn_memories;
//	std::vector<mkldnn::primitive*> mkldnn_primitives;
	std::vector<AlignedBuffer*> memory_buffers;
//	std::vector<mkldnn::memory::desc*> mkldnn_scratchpad_mds;
//	AlignedBuffer* scratchpad_buffer;
//	std::vector<char*> mkldnn_workspaces;
//#if defined(NGRAPH_TBB_ENABLE)
//	tbb::flow::graph* G;
//	tbb::global_control* c;
//#endif
//	State* const* states;
//	std::set<size_t> breakpoints;
//	size_t pc;
//#ifdef NGRAPH_MLIR_ENABLE
//	/// Maps CompiledKernel nodes to their MLIR compiler
//	/// The MLIR compiler caches the compiled code on the first invocation,
//	/// and may in the future support re-compilation
//	std::unordered_map<ngraph::op::CompiledKernel*,
//					   ngraph::runtime::ngmlir::MLIRCPURuntime>
//		mlir_runtimes;
//#endif

    CPURuntimeContext();
    ~CPURuntimeContext();
};
CPURuntimeContext::CPURuntimeContext()
{
	first_iteration = true;
	p_en = new bool(false);
	auto buffer = new AlignedBuffer(200000*4096, 64);
	memory_buffers.push_back(buffer);
}
CPURuntimeContext::~CPURuntimeContext()
{
	delete p_en;

	for (auto p : memory_buffers)
	{
		delete p;
	}
}
extern "C" CPURuntimeContext* init_cpu_ctx()
{
	return new CPURuntimeContext;
}

extern "C" void destroy_cpu_ctx(CPURuntimeContext* cpu_ctx)
{
    delete cpu_ctx;
}


struct CPURuntimeContextCG
{
#if defined(NGRAPH_TBB_ENABLE)
    std::unique_ptr<tbb::flow::graph> tbb_graph;
    std::unique_ptr<tbb::global_control> tbb_gcontrol;

    CPURuntimeContextCG() { init_tbb(); init_mkldnn_primitives();}
    ~CPURuntimeContextCG() { cleanup_tbb(); cleanup_mkldnn_primitives();}
#else
    CPURuntimeContextCG() { init_mkldnn_primitives();}
    ~CPURuntimeContextCG() { cleanup_mkldnn_primitives();}
#endif

    std::vector<mkldnn::memory*> mkldnn_memories;
    std::vector<mkldnn::primitive*> mkldnn_primitives;
    std::vector<mkldnn::memory::desc*> mkldnn_scratchpad_mds;
    AlignedBuffer* scratchpad_buffer;
    std::vector<char*> mkldnn_workspaces;
    std::vector<mkldnn::memory::desc*> mkldnn_descriptors;

    mkldnn::engine global_cpu_engine = mkldnn::engine(mkldnn::engine::kind::cpu, 0);

    void set_memory_ptr(size_t index,
                        void* ptr)
	{
		auto memory = mkldnn_memories[index];
		memory->set_data_handle(ptr);
	}

    void mkldnn_invoke_primitive(size_t primitive_index, std::vector<size_t>& deps,
                                        OpType type, size_t scratchpad_size)
	{
        std::unordered_map<int, mkldnn::memory> exec_args;
        size_t nargs;
        switch (type)
        {
        case OpType::ADD:
            exec_args = {{MKLDNN_ARG_MULTIPLE_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_MULTIPLE_SRC + 1, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[2]]}};
            break;
        case OpType::AVGPOOL:
        case OpType::BOUNDEDRELU:
        case OpType::CONVERTLAYOUT:
        case OpType::LEAKYRELU:
        case OpType::LRN:
        case OpType::MAXPOOL:
        case OpType::QUANTIZE:
        case OpType::DEQUANTIZE:
        case OpType::QUANTIZEDAVGPOOL:
        case OpType::QUANTIZEDMAXPOOL:
        case OpType::RELU:
        case OpType::SIGMOID:
        case OpType::SLICE:
        case OpType::SOFTMAX:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[1]]}};
            break;
        case OpType::AVGPOOLBACKPROP:
            exec_args = {{MKLDNN_ARG_DIFF_DST, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_DIFF_SRC, *mkldnn_memories[deps[1]]}};
            break;
        case OpType::BATCHNORM3ARGS:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_WEIGHTS, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_MEAN, *mkldnn_memories[deps[3]]},
                         {MKLDNN_ARG_VARIANCE, *mkldnn_memories[deps[4]]}};
            break;
        case OpType::BATCHNORM5ARGS:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_MEAN, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_VARIANCE, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_WEIGHTS, *mkldnn_memories[deps[3]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[4]]}};
            break;
        case OpType::BATCHNORMBACKPROP:
            exec_args = {{MKLDNN_ARG_WEIGHTS, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_SRC, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_MEAN, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_VARIANCE, *mkldnn_memories[deps[3]]},
                         {MKLDNN_ARG_DIFF_DST, *mkldnn_memories[deps[4]]},
                         {MKLDNN_ARG_DIFF_SRC, *mkldnn_memories[deps[5]]},
                         {MKLDNN_ARG_DIFF_WEIGHTS, *mkldnn_memories[deps[6]]}};
            break;
        case OpType::CONCAT:
        case OpType::QUANTIZEDCONCAT:
            nargs = deps.size() - 1;
            for (size_t i = 0; i < nargs; i++)
            {
                exec_args.insert({MKLDNN_ARG_MULTIPLE_SRC + i, *mkldnn_memories[deps[i]]});
            }
            exec_args.insert({MKLDNN_ARG_DST, *mkldnn_memories[deps[nargs]]});
            break;
        case OpType::CONVOLUTION:
        case OpType::CONVOLUTIONRELU:
        case OpType::CONVOLUTIONADD:
        case OpType::GROUPCONVOLUTION:
        case OpType::QUANTIZEDMATMUL:
        case OpType::QUANTIZEDCONVOLUTION:
        case OpType::QUANTIZEDCONVOLUTIONRELU:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_WEIGHTS, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[2]]}};
            break;
        case OpType::CONVOLUTIONBIAS:
        case OpType::CONVOLUTIONBIASADD:
        case OpType::GROUPCONVOLUTIONBIAS:
        case OpType::QUANTIZEDCONVOLUTIONBIAS:
        case OpType::QUANTIZEDCONVOLUTIONBIASADD:
        case OpType::QUANTIZEDCONVOLUTIONBIASSIGNEDADD:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_WEIGHTS, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_BIAS, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[3]]}};
            break;
        case OpType::QUANTIZEDDOTBIAS:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_WEIGHTS, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_BIAS, *mkldnn_memories[deps[3]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[2]]}};
            break;
        case OpType::CONVOLUTIONBACKPROPDATA:
            exec_args = {{MKLDNN_ARG_DIFF_DST, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_WEIGHTS, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_DIFF_SRC, *mkldnn_memories[deps[2]]}};
            break;
        case OpType::CONVOLUTIONBACKPROPWEIGHTS:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_DIFF_DST, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_DIFF_WEIGHTS, *mkldnn_memories[deps[2]]}};
            break;
        case OpType::CONVOLUTIONBIASBACKPROPWEIGHTSBIAS:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_DIFF_DST, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_DIFF_WEIGHTS, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_DIFF_BIAS, *mkldnn_memories[deps[3]]}};
            break;
        case OpType::DECONVOLUTIONBIAS:
            exec_args = {{MKLDNN_ARG_WEIGHTS, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_SRC, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_BIAS, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[3]]}};
            break;
        case OpType::LSTM:
        case OpType::RNN:
            exec_args = {{MKLDNN_ARG_SRC_LAYER, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_SRC_ITER, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_SRC_ITER_C, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_WEIGHTS_LAYER, *mkldnn_memories[deps[3]]},
                         {MKLDNN_ARG_WEIGHTS_ITER, *mkldnn_memories[deps[4]]},
                         {MKLDNN_ARG_BIAS, *mkldnn_memories[deps[5]]},
                         {MKLDNN_ARG_DST_LAYER, *mkldnn_memories[deps[6]]},
                         {MKLDNN_ARG_DST_ITER, *mkldnn_memories[deps[7]]},
                         {MKLDNN_ARG_DST_ITER_C, *mkldnn_memories[deps[8]]},
                         {MKLDNN_ARG_WORKSPACE, *mkldnn_memories[deps[9]]}};
            break;
        case OpType::MAXPOOLBACKPROPFORWARD:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_WORKSPACE, *mkldnn_memories[deps[3]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[2]]}};
            break;
        case OpType::MAXPOOLWITHINDICES:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_WORKSPACE, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_DST, *mkldnn_memories[deps[1]]}};
            break;
        case OpType::MAXPOOLBACKPROPBACKWARD:
            exec_args = {{MKLDNN_ARG_DIFF_DST, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_WORKSPACE, *mkldnn_memories[deps[3]]},
                         {MKLDNN_ARG_DIFF_SRC, *mkldnn_memories[deps[2]]}};
		    break;
        case OpType::MAXPOOLWITHINDICESBACKPROP:
            exec_args = {{MKLDNN_ARG_DIFF_DST, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_WORKSPACE, *mkldnn_memories[deps[2]]},
                         {MKLDNN_ARG_DIFF_SRC, *mkldnn_memories[deps[1]]}};
            break;
        case OpType::RELUBACKPROP:
        case OpType::SIGMOIDBACKPROP:
            exec_args = {{MKLDNN_ARG_SRC, *mkldnn_memories[deps[0]]},
                         {MKLDNN_ARG_DIFF_DST, *mkldnn_memories[deps[1]]},
                         {MKLDNN_ARG_DIFF_SRC, *mkldnn_memories[deps[2]]}};
            break;
        }

        if (scratchpad_size)
        {
            mkldnn::memory scratchpad(*mkldnn_scratchpad_mds[primitive_index],
                                      global_cpu_engine,
                                      scratchpad_buffer->get_ptr());
            exec_args.insert({MKLDNN_ARG_SCRATCHPAD, scratchpad});
        }

        mkldnn::stream s(global_cpu_engine);
        try
        {
            (*mkldnn_primitives[primitive_index]).execute(s, exec_args);
            s.wait();
        }
        catch (const mkldnn::error& e)
        {
            throw std::runtime_error("Could not run mkdnn primitive " + std::string(e.message));
        }
    }

private:
#if defined(NGRAPH_TBB_ENABLE)
    inline void init_tbb()
    {
        if (std::getenv("NGRAPH_CPU_USE_TBB"))
        {
            tbb_graph.reset(new tbb::flow::graph);
            const char* env_parallelism = std::getenv("NGRAPH_INTER_OP_PARALLELISM");
            const int parallelism = env_parallelism == nullptr ? 1 : std::atoi(env_parallelism);
            tbb_gcontrol.reset(
                new tbb::global_control(tbb::global_control::max_allowed_parallelism, parallelism));
        }
    }

    inline void cleanup_tbb()
    {
        if (std::getenv("NGRAPH_CPU_USE_TBB"))
        {
            // Delete nodes in tbb_graph.
            tbb_graph->wait_for_all();
            std::vector<tbb::flow::graph_node*> to_be_deleted;
            for (auto it = tbb_graph->begin(); it != tbb_graph->end(); it++)
            {
                to_be_deleted.push_back(&*it);
            }
            for (auto* node : to_be_deleted)
            {
                delete node;
            }
        }
    }
#endif

    void init_mkldnn_primitives();

	inline void cleanup_mkldnn_primitives()
	{
		for (auto p : mkldnn_primitives)
		{
			delete p;
		}
	    for (auto m : mkldnn_memories)
		{
			delete m;
		}
        for (auto s : mkldnn_scratchpad_mds)
        {
            delete s;
        }
        delete scratchpad_buffer;
		
#ifndef _WIN32
        //To avoid memory leak in mkldnn, release any buffers that are not free'd yet.
        //https://software.intel.com/en-us/mkl-linux-developer-guide-avoiding-memory-leaks-in-intel-mkl
        //mkl_free_buffers() is not exposed at this point, hence using mkl_serv_free_buffers()
//        ngraph::runtime::cpu::mkldnn_utils::mkl_serv_free_buffers();
#endif

        for (auto w : mkldnn_workspaces)
        {
            free(w);
        }
    }

    inline void cleanup_mkldnn_descriptors()
    {
        for (auto d : mkldnn_descriptors)
        {
            free(d);
        }
    }
};

extern "C" CPURuntimeContextCG* init_cg_ctx()
{
    return new CPURuntimeContextCG;
}

extern "C" void destroy_cg_ctx(CPURuntimeContextCG* cg_ctx)
{
    delete cg_ctx;
}

static void
	deserialize_memory_descs_and_build_memory(std::ifstream& desc_file,
														 CPURuntimeContextCG* cg_ctx,
														 size_t descs_count)
{
    cg_ctx->mkldnn_descriptors = std::vector<mkldnn::memory::desc*>(descs_count);
    for (auto i = 0; i < descs_count; i++)
    {
    		size_t index;
		    desc_file >> index;
        auto desc = (mkldnn::memory::desc*)malloc(sizeof(mkldnn::memory::desc));
        if (!desc)
        {
            throw std::bad_alloc();
        }
        desc_file.read(reinterpret_cast<char*>(desc), sizeof(mkldnn::memory::desc));

		    cg_ctx->mkldnn_descriptors[i] = desc;
		    cg_ctx->mkldnn_memories[index] = new mkldnn::memory(*cg_ctx->mkldnn_descriptors[i], cg_ctx->global_cpu_engine, nullptr);
	}
};


void inline CPURuntimeContextCG::init_mkldnn_primitives()
{
    mkldnn_primitives = std::vector<mkldnn::primitive*>(5);
    mkldnn_memories = std::vector<mkldnn::memory*>(14);
    mkldnn_scratchpad_mds = std::vector<mkldnn::memory::desc*>(5);
    size_t scratchpad_size = 248371263;
    if (scratchpad_size > 0)
    {
        size_t alignment = 4096;
        scratchpad_buffer = new AlignedBuffer(scratchpad_size, alignment);
    }
    else
    {
        scratchpad_buffer = nullptr;
    }
}

bool Function_0_t_en[10];
//extern "C" void Function_0(void** inputs, void** outputs, cpu::CPURuntimeContext* ctx, CPURuntimeContextCG* cg_ctx)
extern "C" void Function_0(void** inputs, void** outputs, CPURuntimeContext* ctx, CPURuntimeContextCG* cg_ctx)
{
    if (ctx->first_iteration)
    {
        // read in memory descriptors and build mkldnn primitives
        std::ifstream desc_file ("desc_file", std::ios::binary);
	if (desc_file.fail())
	{cout << endl <<"Failed to load desc file: " << __FILE__ << "line " << __LINE__ << endl;
	exit(0);}
        deserialize_memory_descs_and_build_memory(desc_file, cg_ctx, 14);
    }
    size_t pool_base_ptr = (size_t) ctx->memory_buffers[0]->get_ptr();

    bool* t_en = (bool*)Function_0_t_en;

    // ConvolutionBias_815(Parameter_0_0, Constant_1_0, Constant_3_0, ConvolutionBias_815_0)
    if (ctx->first_iteration  || ctx->p_en[0]) {
        if (ctx->first_iteration)
        {
            // Write in memory descriptors

            // build QConv primitive descriptor
            auto conv_desc = mkldnn::convolution_forward::desc(mkldnn::prop_kind::forward,
            mkldnn::algorithm::convolution_direct,
            *cg_ctx->mkldnn_descriptors[0],
            *cg_ctx->mkldnn_descriptors[1],
            *cg_ctx->mkldnn_descriptors[2],
            *cg_ctx->mkldnn_descriptors[3],
            mkldnn::memory::dims{1, 1}, 
            mkldnn::memory::dims{1, 1}, 
            mkldnn::memory::dims{6, 4}, 
            mkldnn::memory::dims{6, 4});
            mkldnn::post_ops ops;
            const float ops_scale = 1.f;
            const float ops_alpha = -0.f; // relu negative slope
            const float ops_beta = 0.f;
            ops.append_eltwise(ops_scale, mkldnn::algorithm::eltwise_relu, ops_alpha, ops_beta);
            mkldnn::primitive_attr conv_attr;
            conv_attr.set_post_ops(ops);
            conv_attr.set_scratchpad_mode(mkldnn::scratchpad_mode::user);
            auto conv_pd = mkldnn::convolution_forward::primitive_desc(conv_desc, conv_attr, cg_ctx->global_cpu_engine);
            cg_ctx->mkldnn_primitives[0] = new mkldnn::convolution_forward(conv_pd);
            cg_ctx->mkldnn_scratchpad_mds[0] = new mkldnn::memory::desc(conv_pd.scratchpad_desc());
        }
        cg_ctx->set_memory_ptr(0, (((float*)(inputs[0])) + 0));
        cg_ctx->set_memory_ptr(1, Constant_1_0);
        cg_ctx->set_memory_ptr(2, Constant_3_0);
        cg_ctx->set_memory_ptr(3, ((float*)(pool_base_ptr + 0)));
        std::vector<size_t> deps{0, 1, 2, 3};
        cg_ctx->mkldnn_invoke_primitive(0, deps, OpType::CONVOLUTIONBIAS, 248371263);
        t_en[3] = true;
    } else {
        t_en[3] = false;
    }

    // ConvertLayout_822(ConvolutionBias_815_0, ConvertLayout_822_0)
    if (ctx->first_iteration  || t_en[3]) {
        if (ctx->first_iteration)
        {
            mkldnn::primitive_attr attr;
            attr.set_scratchpad_mode(mkldnn::scratchpad_mode::user);

            // build reorder primitive
            auto reorder_pd = mkldnn::reorder::primitive_desc(*cg_ctx->mkldnn_memories[4], *cg_ctx->mkldnn_memories[5], attr);
            cg_ctx->mkldnn_primitives[1] = new mkldnn::reorder(reorder_pd);
            cg_ctx->mkldnn_scratchpad_mds[1] = new mkldnn::memory::desc(reorder_pd.scratchpad_desc());
        }
        cg_ctx->set_memory_ptr(4, ((float*)(pool_base_ptr + 0)));
        cg_ctx->set_memory_ptr(5, ((float*)(pool_base_ptr + 741376)));
        std::vector<size_t> deps{4, 5};
        cg_ctx->mkldnn_invoke_primitive(1, deps, OpType::CONVERTLAYOUT, 0);
        t_en[5] = true;
    } else {
        t_en[5] = false;
    }

    // ConvertLayout_823(Constant_7_0, ConvertLayout_823_0)
    if (ctx->first_iteration ) {
        if (ctx->first_iteration)
        {
            mkldnn::primitive_attr attr;
            attr.set_scratchpad_mode(mkldnn::scratchpad_mode::user);

            // build reorder primitive
            auto reorder_pd = mkldnn::reorder::primitive_desc(*cg_ctx->mkldnn_memories[6], *cg_ctx->mkldnn_memories[7], attr);
            cg_ctx->mkldnn_primitives[2] = new mkldnn::reorder(reorder_pd);
            cg_ctx->mkldnn_scratchpad_mds[2] = new mkldnn::memory::desc(reorder_pd.scratchpad_desc());
        }
        cg_ctx->set_memory_ptr(6, Constant_7_0);
        cg_ctx->set_memory_ptr(7, ((float*)(pool_base_ptr + 1925120)));
        std::vector<size_t> deps{6, 7};
        cg_ctx->mkldnn_invoke_primitive(2, deps, OpType::CONVERTLAYOUT, 0);
        t_en[6] = true;
    } else {
        t_en[6] = false;
    }

    // ConvolutionBias_824(ConvertLayout_822_0, ConvertLayout_823_0, Constant_9_0, ConvolutionBias_824_0)
    if (ctx->first_iteration  || t_en[5] || t_en[6]) {
        if (ctx->first_iteration)
        {
            // Write in memory descriptors

            // build QConv primitive descriptor
            auto conv_desc = mkldnn::convolution_forward::desc(mkldnn::prop_kind::forward,
            mkldnn::algorithm::convolution_direct,
            *cg_ctx->mkldnn_descriptors[8],
            *cg_ctx->mkldnn_descriptors[9],
            *cg_ctx->mkldnn_descriptors[10],
            *cg_ctx->mkldnn_descriptors[11],
            mkldnn::memory::dims{1, 1}, 
            mkldnn::memory::dims{2, 2}, 
            mkldnn::memory::dims{3, 3}, 
            mkldnn::memory::dims{3, 3});
            mkldnn::post_ops ops;
            const float ops_scale = 1.f;
            const float ops_alpha = -0.f; // relu negative slope
            const float ops_beta = 0.f;
            ops.append_eltwise(ops_scale, mkldnn::algorithm::eltwise_relu, ops_alpha, ops_beta);
            mkldnn::primitive_attr conv_attr;
            conv_attr.set_post_ops(ops);
            conv_attr.set_scratchpad_mode(mkldnn::scratchpad_mode::user);
            auto conv_pd = mkldnn::convolution_forward::primitive_desc(conv_desc, conv_attr, cg_ctx->global_cpu_engine);
            cg_ctx->mkldnn_primitives[3] = new mkldnn::convolution_forward(conv_pd);
            cg_ctx->mkldnn_scratchpad_mds[3] = new mkldnn::memory::desc(conv_pd.scratchpad_desc());
        }
        cg_ctx->set_memory_ptr(8, ((float*)(pool_base_ptr + 741376)));
        cg_ctx->set_memory_ptr(9, ((float*)(pool_base_ptr + 1925120)));
        cg_ctx->set_memory_ptr(10, Constant_9_0);
        cg_ctx->set_memory_ptr(11, ((float*)(pool_base_ptr + 1933312)));
        std::vector<size_t> deps{8, 9, 10, 11};
        cg_ctx->mkldnn_invoke_primitive(3, deps, OpType::CONVOLUTIONBIAS, 127);
        t_en[8] = true;
    } else {
        t_en[8] = false;
    }

    // ConvertLayout_825(ConvolutionBias_824_0, ConvertLayout_825_0)
    if (ctx->first_iteration  || t_en[8] || 1) {
        if (ctx->first_iteration)
        {
            mkldnn::primitive_attr attr;
            attr.set_scratchpad_mode(mkldnn::scratchpad_mode::user);

            // build reorder primitive
            auto reorder_pd = mkldnn::reorder::primitive_desc(*cg_ctx->mkldnn_memories[12], *cg_ctx->mkldnn_memories[13], attr);
            cg_ctx->mkldnn_primitives[4] = new mkldnn::reorder(reorder_pd);
            cg_ctx->mkldnn_scratchpad_mds[4] = new mkldnn::memory::desc(reorder_pd.scratchpad_desc());
        }
        cg_ctx->set_memory_ptr(12, ((float*)(pool_base_ptr + 1933312)));
        cg_ctx->set_memory_ptr(13, (((float*)(outputs[0])) + 0));
        std::vector<size_t> deps{12, 13};
        cg_ctx->mkldnn_invoke_primitive(4, deps, OpType::CONVERTLAYOUT, 0);
        t_en[9] = true;
    } else {
        t_en[9] = false;
    }

    // Result_13(ConvertLayout_825_0, Result_13_0)
    if (ctx->first_iteration  || t_en[9] || 1) {
        // Skipping generation for Result_13
        t_en[0] = true;
    } else {
        t_en[0] = false;
    }
    ctx->first_iteration = false;
}

